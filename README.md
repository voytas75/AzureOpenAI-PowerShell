# AzureOpenAI-PowerShell

Welcome to the GitHub repository for Azure OpenAI PowerShell Functions! This project provides a collection of PowerShell functions that allow you to interact with Azure OpenAI's powerful language models, including GPT-3.

[What is Azure OpenAI Service?](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview)

<details>

  <summary>Completion, Chat Completion, and Embedding</summary>

In Azure OpenAI, Completion, Chat Completions, and Embeddings are specific functionalities that leverage the power of language models to perform different tasks. Here's a brief overview of each:

1. **Completion**: Completion is a functionality that allows you to generate text completions based on a given prompt. You provide a partial sentence or context, and the language model continues the text, completing it in a way that makes sense. It's useful for tasks like content generation, text auto-completion, drafting emails, or writing code snippets. Completion models excel at generating human-like text and can provide creative and coherent completions.

2. **Chat Completion**: Chat Completions enable you to simulate interactive conversations with the language model. Instead of providing a single prompt, you provide a series of messages, including user and system messages. The model responds to each message in the conversation, maintaining context and generating appropriate replies. This functionality is particularly useful for building chatbots, virtual assistants, or automating conversational tasks such as customer support interactions.

3. **Embedding**: Embeddings refer to the numerical representations of text generated by the language models. These representations capture the semantic meaning and contextual information of the text. Embeddings allow you to measure similarity between different texts, cluster documents based on their content, or perform other operations that require understanding the relationships between pieces of text. With embeddings, you can enhance your applications with advanced language understanding and processing capabilities.

These functionalities are part of Azure OpenAI's offering and are powered by state-of-the-art language models, such as GPT-3. They provide developers with powerful tools to leverage natural language processing and generation capabilities within their applications, automation workflows, or any task that involves working with text data.

</details>

## Functionalities

- [x] Completion - Function [`Invoke-AzureOpenAICompletion`](https://github.com/voytas75/AzureOpenAI-PowerShell#function-invoke-azureopenaicompletion)
- [ ] Chat completion - Function `Invoke-AzureOpenAIChatCompletion`
- [ ] Embedding - Function `Invoke-AzureOpenAIEmbedding`
- [x] Helper function for displaying information about request parameters - Function [`Invoke-APICall`](https://github.com/voytas75/AzureOpenAI-PowerShell#function-invoke-apicall)

### Function: `Invoke-AzureOpenAICompletion`

This script makes an API request to an AZURE OpenAI and outputs the response message.

This script defines functions to make an API request to an AZURE OpenAI and output the response message. The user can input their own messages and specify various parameters such as temperature and frequency penalty.

#### Parameters

- `APIVersion`: Version of API.
- `Endpoint`: The endpoint to which the request will be sent.
- `Deployment`: The deployment name.
- `MaxTokens`: The maximum number of tokens to generate in the completion.
- `Temperature`: What sampling temperature to use, between 0 and 2. Higher values mean the model will take more risks. Try 0.9 for more creative applications and 0 (argmax sampling) for ones with a well-defined answer.
- `TopP`: An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
- `FrequencyPenalty`: Number between 0 and 2 that penalizes new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
- `PresencePenalty`: Number between 0 and 2 that penalizes new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
- `n`: How many completions to generate for each prompt.
- `best_of`: Generates best_of completions server-side and returns the "best" (the one with the highest log probability per token).
- `Stop`: Up to 4 sequences where the API will stop generating further tokens.
- `Stream`: Whether to stream back partial progress.
- `logit_bias`: Controls sampling by adding a bias term to the logits.
- `logprobs`: Include the log probabilities on the logprobs most likely tokens.
- `suffix`: Attaches a suffix to all prompt texts to help model differentiate prompt from other text encountered during training.
- `echo`: If true, the returned result will include the provided prompt.
- `completion_config`: Configuration object for the completions.
- `User`: The user to which the request will be sent. If empty, the API will select a user automatically.
- `model`: Deployed model to connect to (used in `Deployment`).

#### Usage

```powershell
. .\invoke-AzureOpenAiCompletion.ps1

Invoke-AzureOpenAICompletion `
    -APIVersion "2023-06-01-preview" `
    -Endpoint "https://example.openai.azure.com" `
    -Deployment "example_model_gpt35_1" `
    -model "gpt-35-turbo" `
    -MaxTokens 500 `
    -Temperature 0.7 `
    -TopP 0.8 `
    -User "BobbyK"
```

This example makes an API request to an AZURE OpenAI and outputs the response message.

### Function: `Invoke-APICall`

Helper function for displaying information about request parameters of AZURE OpenAI API version.

#### Syntax

```powershell
.\Invoke-APICall -RawAPIUrl <string>
```

#### Parameters

- `-RawAPIUrl` (Required): Specifies the URL of the API endpoint to make the request to.

#### Example

```powershell
Invoke-APICall -RawAPIUrl 'https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/preview/2023-06-01-preview/inference.json'
```

#### Output

The function retrieves the specification REST API for AZURE OpenAI version '2023-06-01-preview' <https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/preview/2023-06-01-preview>.

Other versions:<https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference>.
